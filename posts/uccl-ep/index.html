<!DOCTYPE html><html lang="en"> <head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/svg+xml" href="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/images/uccl_logo.png"><meta name="generator" content="Astro v5.1.1"><!-- Canonical URL --><link rel="canonical" href="https://uccl-project.github.io/posts/uccl-ep/"><!-- Sitemap --><link rel="sitemap" href="/sitemap-index.xml"><!-- Primary Meta Tags --><title>Previewing UCCL-EP: Flexible and Efficient Expert Parallelism for Cloud and Beyond</title><meta name="title" content="Previewing UCCL-EP: Flexible and Efficient Expert Parallelism for Cloud and Beyond"><meta name="description" content="GPU-driven communication (e.g., DeepEP) is the key to efficient and large-scale EP, but it cannot run on heterogeneous platforms in the public cloud due to tight coupling between GPU and NIC."><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://uccl-project.github.io/posts/uccl-ep/"><meta property="og:title" content="Previewing UCCL-EP: Flexible and Efficient Expert Parallelism for Cloud and Beyond"><meta property="og:description" content="GPU-driven communication (e.g., DeepEP) is the key to efficient and large-scale EP, but it cannot run on heterogeneous platforms in the public cloud due to tight coupling between GPU and NIC."><meta property="og:image" content="https://uccl-project.github.io/blog-placeholder-1.avif"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://uccl-project.github.io/posts/uccl-ep/"><meta property="twitter:title" content="Previewing UCCL-EP: Flexible and Efficient Expert Parallelism for Cloud and Beyond"><meta property="twitter:description" content="GPU-driven communication (e.g., DeepEP) is the key to efficient and large-scale EP, but it cannot run on heterogeneous platforms in the public cloud due to tight coupling between GPU and NIC."><meta property="twitter:image" content="https://uccl-project.github.io/blog-placeholder-1.avif"><!-- Preline CSS --><script type="module" src="/_astro/BaseHead.astro_astro_type_script_index_0_lang.BtT675nX.js"></script><!-- Prism syntax highlighting --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-3wzg3yUeG6mXQz0YIZxZOKhHvJ3C0cI85FhF38sZ4N2VNivXzXcX4Jt9I7H5PHeTtNKgHdwNwp0UrEG3iu8IRw==" crossorigin="anonymous" referrerpolicy="no-referrer"><!-- Custom CSS for table borders --><link rel="stylesheet" href="/_astro/_page_.n-8wRpcs.css">
<style>[data-astro-image]{width:100%;height:auto;-o-object-fit:var(--fit);object-fit:var(--fit);-o-object-position:var(--pos);object-position:var(--pos);aspect-ratio:var(--w) / var(--h)}[data-astro-image=responsive]{max-width:calc(var(--w) * 1px);max-height:calc(var(--h) * 1px)}[data-astro-image=fixed]{width:calc(var(--w) * 1px);height:calc(var(--h) * 1px)}
</style><script type="module" src="/_astro/page.DTIbhfSr.js"></script>
<script>!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=Object.assign(w[p]||{},{"lib":"/~partytown/","debug":false});c[f]=(c[f]||[]).concat(["dataLayer.push"])})(window,'partytown','forward');/* Partytown 0.10.2 - MIT builder.io */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(v,1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(e){p=r.createElement(e?"script":"iframe"),t._pttab=Date.now(),e||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(e?"atomics.js?v=0.10.2":"sandbox-sw.html?"+t._pttab),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);;(e=>{e.addEventListener("astro:before-swap",e=>{let r=document.body.querySelector("iframe[src*='/~partytown/']");if(r)e.newDocument.body.append(r)})})(document);</script></head> <body class="flex flex-col min-h-screen mx-auto max-w-4xl px-4 dark:prose-invert sm:px-6 lg:px-8 dark:bg-neutral-900"> <header class="flex flex-wrap md:justify-start md:flex-nowrap z-50 w-full py-7"> <nav class="relative max-w-7xl w-full flex flex-wrap md:grid md:grid-cols-12 basis-full items-center px-4 mx-auto" aria-label="Global"> <div class="md:col-span-3"> <a class="flex-none text-xl font-semibold text-neutral-900 hover:text-neutral-600 dark:text-neutral-400 dark:hover:text-neutral-200" href="/" aria-label="Astroverse"> UCCL </a> </div> <div class="flex items-center gap-x-2 ms-auto py-1 md:ps-6 md:order-3 md:col-span-3"> <button type="button" class="py-2 px-3 inline-flex items-center gap-x-2 text-sm font-medium rounded-xl border border-transparent text-black hover:bg-neutral-100 dark:text-white dark:hover:bg-neutral-700 transition disabled:opacity-50 disabled:pointer-events-none" onclick="window.location.href='/search/'"> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:search">   <symbol id="ai:tabler:search" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 10a7 7 0 1 0 14 0a7 7 0 1 0-14 0m18 11l-6-6"/></symbol><use href="#ai:tabler:search"></use>  </svg> </button> <button type="button" class="hs-dark-mode hs-dark-mode-active:hidden inline-flex items-center gap-x-2 py-2 px-3 rounded-full text-sm text-black hover:bg-white/20" data-hs-theme-click-value="dark"> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:sun-filled">   <symbol id="ai:tabler:sun-filled" viewBox="0 0 24 24"><path fill="currentColor" d="M12 19a1 1 0 0 1 .993.883L13 20v1a1 1 0 0 1-1.993.117L11 21v-1a1 1 0 0 1 1-1m6.313-2.09l.094.083l.7.7a1 1 0 0 1-1.32 1.497l-.094-.083l-.7-.7a1 1 0 0 1 1.218-1.567zm-11.306.083a1 1 0 0 1 .083 1.32l-.083.094l-.7.7a1 1 0 0 1-1.497-1.32l.083-.094l.7-.7a1 1 0 0 1 1.414 0M4 11a1 1 0 0 1 .117 1.993L4 13H3a1 1 0 0 1-.117-1.993L3 11zm17 0a1 1 0 0 1 .117 1.993L21 13h-1a1 1 0 0 1-.117-1.993L20 11zM6.213 4.81l.094.083l.7.7a1 1 0 0 1-1.32 1.497l-.094-.083l-.7-.7A1 1 0 0 1 6.11 4.74zm12.894.083a1 1 0 0 1 .083 1.32l-.083.094l-.7.7a1 1 0 0 1-1.497-1.32l.083-.094l.7-.7a1 1 0 0 1 1.414 0M12 2a1 1 0 0 1 .993.883L13 3v1a1 1 0 0 1-1.993.117L11 4V3a1 1 0 0 1 1-1m0 5a5 5 0 1 1-4.995 5.217L7 12l.005-.217A5 5 0 0 1 12 7"/></symbol><use href="#ai:tabler:sun-filled"></use>  </svg> </button> <button type="button" class="hs-dark-mode hs-dark-mode-active:inline-flex hidden items-center gap-x-2 py-2 px-3 rounded-full text-sm text-white hover:bg-white/20" data-hs-theme-click-value="light"> <svg width="1em" height="1em" class="icon-base" data-icon="tabler:moon-filled">   <symbol id="ai:tabler:moon-filled" viewBox="0 0 24 24"><path fill="currentColor" d="M12 1.992a10 10 0 1 0 9.236 13.838c.341-.82-.476-1.644-1.298-1.31a6.5 6.5 0 0 1-6.864-10.787l.077-.08c.551-.63.113-1.653-.758-1.653h-.266l-.068-.006z"/></symbol><use href="#ai:tabler:moon-filled"></use>  </svg> </button> <div class="md:hidden"> <button type="button" class="hs-collapse-toggle size-[38px] flex justify-center items-center text-sm font-semibold rounded-xl text-black hover:bg-neutral-100 disabled:opacity-50 disabled:pointer-events-none dark:text-white dark:hover:bg-neutral-700" data-hs-collapse="#navbar-collapse-with-animation" aria-controls="navbar-collapse-with-animation" aria-label="Toggle navigation"> <svg width="1em" height="1em" class="hs-collapse-open:hidden flex-shrink-0 size-4" data-icon="tabler:menu-2">   <symbol id="ai:tabler:menu-2" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></symbol><use href="#ai:tabler:menu-2"></use>  </svg> <svg width="1em" height="1em" class="hs-collapse-open:block hidden flex-shrink-0 size-4" data-icon="tabler:menu-order">   <symbol id="ai:tabler:menu-order" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 10h16M4 14h16M9 18l3 3l3-3M9 6l3-3l3 3"/></symbol><use href="#ai:tabler:menu-order"></use>  </svg> </button> </div> </div> <div id="navbar-collapse-with-animation" class="hs-collapse hidden overflow-hidden transition-all duration-300 basis-full grow md:block md:w-auto md:basis-auto md:order-2 md:col-span-6"> <div class="flex flex-col gap-y-4 gap-x-0 mt-5 md:flex-row md:justify-center md:items-center md:gap-y-0 md:gap-x-7 md:mt-0"> <a href="/posts/about-us/" class="px-4 py-3 font-medium text-neutral-900 hover:text-neutral-600 dark:text-neutral-400 dark:hover:text-neutral-200"> About Us </a><a href="/category/One/1/" class="px-4 py-3 font-medium text-neutral-900 hover:text-neutral-600 dark:text-neutral-400 dark:hover:text-neutral-200"> Blog Posts </a><a href="/tags/" class="px-4 py-3 font-medium text-neutral-900 hover:text-neutral-600 dark:text-neutral-400 dark:hover:text-neutral-200"> Sort by Tags </a> </div> </div> </nav> </header> <main class="flex-grow">  <main> <article class="prose mx-auto dark:prose-invert"> <div class="prose-h1 text-center"> <h1>Previewing UCCL-EP: Flexible and Efficient Expert Parallelism for Cloud and Beyond</h1> </div> <div> <picture> <source srcset="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/uccl-ep/uccl-ep.png 392w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/uccl-ep/uccl-ep.png 700w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/uccl-ep/uccl-ep.png 980w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/uccl-ep/uccl-ep.png 1960w" type="image/avif" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px">  <img src="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/uccl-ep/uccl-ep.png" srcset="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/uccl-ep/uccl-ep.png 392w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/uccl-ep/uccl-ep.png 700w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/uccl-ep/uccl-ep.png 980w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/uccl-ep/uccl-ep.png 1960w" alt="UCCL-EP" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px" width="1024" height="1024" loading="lazy" decoding="async" class="mx-auto w-full max-w-full rounded-lg"> </picture> </div> <div> <p>
<strong>By: <a href="https://maoziming.github.io/">Ziming Mao</a> (UC Berkeley), <a href="https://yangzhou1997.github.io/">Yang Zhou</a> (UC Davis), <a href="github.com/CalebZ9909" class="no-github-icon">Yihan Zhang</a> (UC Davis), <a href="https://github.com/HermesCui" class="no-github-icon">Chihan Cui</a> (UW-Madison), <a href="https://zhongjiechen.github.io/" class="no-github-icon">Zhongjie Chen</a> (Tsinghua), <a href="https://xuzhiying9510.github.io/">Zhiying Xu</a> (AWS), and other UCCL-EP contributors
<br>
Date: Oct 27, 2025
</strong>
</p>
<div class="tldr">
<p>
GPU-driven communication (e.g., DeepEP) is the key to efficient and large-scale EP, but it cannot run on heterogeneous platforms in the public cloud due to tight coupling between GPU and NIC. UCCL-EP has exactly the same interface and functionality as DeepEP, but allows you to run GPU-driven communication for MoE models on public clouds, such as AWS, with superior performance to the state-of-the-art. Our ultimate goal with UCCL-EP is to democratize EP for heterogeneous GPUs and NIC vendors, including AMD GPUs, Broadcom NICs, AMD Pensando NICs, and more. UCCL-EP open-source: <a href="https://github.com/uccl-project/uccl/tree/main/ep">uccl-project/uccl/ep</a>
</p>
</div>
<h2 id="expert-parallelism-ep">Expert Parallelism (EP)</h2>
<p><strong>Expert Parallelism (EP)</strong> is widely used in large-scale Mixture-of-Experts (MoE) models, where different subsets of the model’s “experts” are placed on different GPUs across multiple nodes. During inference or training, each input token is routed—based on a learned gating function—to one or a few selected experts.</p>
<p>This selective routing requires frequent <strong>dispatch</strong> (sending token embeddings to the correct expert GPUs) and <strong>combine</strong> (gathering expert outputs back to their original positions) operations across the network. These data exchanges are typically performed using Remote Direct Memory Access (RDMA) over high-speed interconnects such as InfiniBand or RoCE.</p>
<p align="center">
  <img src="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/uccl-ep/ep-overview.png" alt="EP illustration" width="600">
  <em>Figure 1: Expert parallelism communication involves frequent dispatch and combine operations across multiple GPUs and nodes. 
</em>
</p>
<p>Unlike traditional data or tensor parallelism, where communication involves large contiguous tensors (on the order of megabytes or gigabytes), EP communication is highly <strong>fine-grained</strong>. Each dispatch or combine operation often involves <strong>small message sizes</strong>—for example, 7 KB (inference) to 256 KB (training) in models like <strong>DeepSeek V3</strong>. Such small message sizes pose a challenge for <strong>general-purpose collective communication libraries</strong> like NCCL, which are optimized for high-throughput transfers of large payloads (e.g., in all-reduce or all-gather operations). When messages are this small, the per-transfer latency and synchronization overhead dominate, leading to poor utilization of network bandwidth. Consequently, EP systems often require <strong>custom, low-latency communication runtimes</strong> that can overlap computation and communication efficiently and handle a large number of concurrent small-message operations.</p>
<p>One popular library for EP is <strong>DeepEP</strong>, which leverages NVIDIA-specific NVSHMEM/IBGDA techniques to let NVIDIA GPUs directly issue RDMA operations to NVIDIA NICs for small-message efficiency. IBGDA essentially runs the NIC driver functions inside the GPU SM cores, so that the GPUs can talk to NICs, bypassing the CPU. The GPU can thus enqueue RDMA writes, reads, or atomic operations straight to the NIC’s doorbell registers. However, while DeepEP has high performance, it suffers from two limitations caused by such <strong>tight coupling between GPUs and NICs</strong>.</p>
<hr>
<h2 id="limitations-of-tightly-coupling-nic-and-gpu">Limitations of Tightly Coupling NIC and GPU</h2>
<h3 id="lack-of-portability">Lack of Portability</h3>
<p>DeepEP is tightly coupled with the <strong>NVIDIA software and hardware ecosystem</strong>. It depends on NVIDIA GPUs, NVIDIA NICs, and their proprietary networking stack (e.g., NVSHMEM, GPUDirect, and IBGDA). As a result, DeepEP can only run on NVIDIA-controlled platforms where these components are co-designed and supported.</p>
<p>This design significantly limits portability. For instance, DeepEP cannot run on <strong>AWS cloud instances</strong>, which use <strong>Elastic Fabric Adapter (EFA)</strong> RDMA NICs instead of NVIDIA hardware. Similar incompatibilities arise on other public clouds and data center environments that deploy non-NVIDIA RDMA solutions, such as <strong>Broadcom Thor NICs</strong>, <strong>Google Cloud Falcon NICs</strong>, and <strong>AMD Pensando NICs</strong>. The same restriction applies to GPU vendors—DeepEP’s reliance on NVIDIA-specific APIs and device driver interfaces makes it difficult, if not impossible, to run on <strong>AMD or Intel GPUs</strong>, even when comparable RDMA-capable networking hardware is present.</p>
<p>This lack of cross-vendor portability increasingly limits deployment flexibility as modern AI clusters become more heterogeneous across GPU architectures and networking fabrics.</p>
<h3 id="lack-of-control-and-visibility">Lack of Control and Visibility</h3>
<p>By moving NIC driver logic into GPU threads, DeepEP sacrifices <strong>fine-grained control and observability</strong> over the communication process. In traditional CPU-driven RDMA systems, the host manages <strong>flow control</strong>, <strong>queue depth</strong>, <strong>completion notifications</strong>, and <strong>load balancing across multiple network queues</strong>. These mechanisms are essential for ensuring fairness, congestion avoidance, and recovery under high network pressure.</p>
<p>In the IBGDA model, however, GPUs issue RDMA operations directly without the CPU’s coordination. This makes it difficult to monitor or regulate traffic. For example, the GPU may post many outstanding RDMA writes without global awareness of NIC queue utilization, leading to congestion or dropped completions. Detecting transfer completion or handling network backpressure is also not possible in DeepEP, as IBGDA or NVSHMEM does not expose relevant interfaces.</p>
<hr>
<h2 id="uccl-ep">UCCL-EP</h2>
<p>UCCL-EP directly tackles these tight-coupling issues and proposes a flexible yet efficient EP solution for the public cloud and heterogeneous device vendors, including GPU and NICs. UCCL-EP preserves the same APIs as DeepEP, supporting both the low latency (for inference) and normal mode (for training).</p>
<p>The core insight of UCCL-EP is that efficient expert-parallel communication, while benefiting from GPU <strong>initiation</strong>, does not require GPUs to <strong>directly</strong> control the NIC. Instead, UCCL-EP restores a clean separation of concerns between compute and control:</p>
<ul>
<li>GPUs retain their massive parallelism for data-intensive tasks — such as token packing, expert combination, NVL forwarding, and local RDMA buffering, and efficient overlap with the background RDMA communication. GPU still initiates communication.</li>
<li>CPUs handle the control-intensive aspects of networking — including queue management, flow control, completion handling, and load balancing — through a lightweight, multi-threaded CPU proxy.</li>
</ul>
<p>Essentially, <strong>UCCL-EP decouples GPU computation from direct NIC control</strong>. Instead of having GPUs post RDMA operations directly to the NIC (as in NVIDIA’s IBGDA model), each GPU forwards <strong>lightweight control commands</strong>—such as “write this token to peer X”—to the CPU through a high-speed shared memory channel. A pool of <strong>multi-threaded CPU proxies</strong> then interprets these commands and issues the actual RDMA verbs to the NIC on the GPU’s behalf.</p>
<p>We note that UCCL-EP’s approach shares similarity with NVSHMEM’s IBRC solution that uses CPU proxies as well, but differs from them by leveraging multiple CPU proxy threads for performance, and supporting a wide range of vendors for portability.</p>
<p align="center">
  <img src="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/uccl-ep/ep-illustration.png" alt="UCCL-EP illustration" width="600">
  <em>Figure 2: RDMA commands initiated by the GPU are handed off to multiple CPU proxy threads. 
</em>
</p>
<p>This design exploits a key observation: every RDMA NIC already exposes a standardized, vendor-neutral interface via the <strong>libibverbs</strong> library, maintained by the Linux-RDMA community. By having GPUs forward RDMA requests to CPU threads over PCIe, while communication is still initiated by GPUs, UCCL-EP can issue network operations on behalf of GPUs using the same verbs API that any NIC driver supports.</p>
<p>The second observation underlying UCCL-EP’s design is that <strong>CPU–GPU communication latency is not the dominant bottleneck</strong>. Modern interconnects such as PCIe Gen5, NVLink, and C2C (chip-to-chip) links offer microsecond-scale latency and tens to hundreds of GB/s bandwidth between CPUs and GPUs. This means that forwarding a control command from the GPU to the CPU is extremely fast—especially compared to the end-to-end latency of an RDMA operation that traverses the network.</p>
<p>Moreover, each control command in expert parallelism typically represents a <strong>batched data movement involving multiple tokens</strong> (e.g., a dispatch or combine operation that transfers tens or hundreds of kilobytes). Therefore, the amortized cost of sending a command descriptor over PCIe is negligible relative to the data volume it represents.</p>
<hr>
<h2 id="designing-an-efficient-cpu-gpu-communication-channel">Designing an Efficient CPU-GPU Communication Channel</h2>
<p>A central challenge in UCCL-EP is building an efficient <strong>forwarding channel between GPUs and CPUs</strong> that can sustain tens of millions of RDMA requests per second without becoming a bottleneck. UCCL-EP implements this channel as a carefully optimized <strong>lock-free FIFO queue</strong> shared between GPU producers and CPU consumers. Each GPU enqueues lightweight RDMA transfer descriptors into the queue, while multiple CPU threads dequeue and execute them through libibverbs.</p>
<p align="center">
  <img src="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/uccl-ep/ep-fifo.png" alt="UCCL-EP FIFO illustration" width="400">
  <em>Figure 3: UCCL-EP employs multiple channels per GPU; The tail is read by CPU thread and allocated on host, the head is read and updated by GPU thread and allocated on device. It further caches the tail value on GPU for faster access. Each TransferCmd is small, occupying only 128 bits. 
</em>
</p>
<p>UCCL-EP employs multiple channels per GPU; The tail is read by CPU thread and allocated on host, the head is read and updated by GPU thread and allocated on device. It further caches the tail value on GPU for faster access. Each TransferCmd is small.</p>
<p>This careful design allows each GPU to achieve over <strong>50 million RDMA operations</strong> per second with modest latency overhead (as shown in UCCL PR <a href="https://github.com/uccl-project/uccl/pull/454">#454</a>), where the NIC’s intrinsic latency and network delay—not the CPU–GPU channel—becomes the dominant cost.</p>
<hr>
<h2 id="working-with-various-gpu-nic-vendors">Working with Various GPU-NIC Vendors</h2>
<p>Different <strong>NIC vendors</strong> introduce additional system-level challenges due to variations in transport protocols and hardware capabilities. For instance, AWS EFA NICs use the <strong>Scalable Reliable Datagram (SRD)</strong> protocol, which employs advanced <strong>multi-pathing</strong> to mitigate congestion at scale. While this design improves throughput and reliability, it breaks the strict in-order delivery guarantee within a single SRD Queue Pair (QP). This becomes problematic for DeepEP-style communication, which relies on ordered RDMA writes followed by atomic operations to notify remote GPUs that writes are delivered to assigned locations in the RDMA transport buffer.</p>
<p>To address this, <strong>UCCL-EP</strong> leverages its CPU-side flexibility to enforce <strong>software-level message ordering</strong>. Each RDMA write carries <strong>immediate data</strong> encoding a per-RDMA-channel sequence number, which the receiver uses to <strong>reorder out-of-sequence messages</strong> before committing them to GPU memory. Importantly, these only apply to control messages (e.g. atomics) and not the data payload.</p>
<p>Furthermore, In DeepEP’s NVIDIA-specific IBGDA path, GPUs rely on <strong>hardware RDMA atomics</strong> to signal remote completion. However, EFA does not natively support RDMA atomics, which poses a correctness challenge: the receiver must still know when a payload has been fully written before it can proceed to read or combine it.</p>
<p>To emulate this behavior, UCCL-EP implements <strong>software-level atomics</strong> using regular RDMA writes and immediate data. The sender writes the payload first, then issues a small RDMA write carrying an immediate value that acts as an atomic message (e.g., the new counter value or flag). On the receiver side, the CPU proxy updates a local completion counter — effectively reproducing the synchronization semantics of hardware atomics.</p>
<p>To enable UCCL EP work with diverse GPU vendors, we have taken the first step in <strong>eliminating nvshmem dependencies</strong>, which is important for portability as well as other features (e.g. elastic scaling). We also observed interestingly, removing nvshmem dependency can sometimes lead to performance improvements, which we suspect to be due to the internal overhead of the nvshmem library.</p>
<hr>
<h2 id="performance">Performance</h2>
<p>On EFA, we observe UCCL-EP significantly outperforms other baselines as we increase the number of tokens in dispatch and combine. We used unmodified <a href="https://github.com/perplexityai/pplx-kernels/tree/master">Perplexity MoE Kernels</a> and ran on H200 with EFA NICs. For the NVSHMEM and Torch baselines, we wrote an efficient packing and unpacking kernel, and relied on their respective AlltoAll APIs to distribute packed tokens to destination ranks in a single contiguous transfer.</p>
<p align="center">
  <img src="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/uccl-ep/ep-efa.png" alt="UCCL-EP EFA results" width="500">
  <em>Figure 4: On 2 nodes, H200 + EFA (400 Gbps)
</em>
</p>
<p>We test normal kernels on H200 (8× GPUs per node) with each node connected to an EFA 400 Gb/s RDMA network card. We follow the DeepSeek-V3 pretraining configuration (4096 tokens per batch, 7168 hidden, top-4 groups, top-8 experts, FP8 dispatch and BF16 combine).</p>








































<table><thead><tr><th align="center">Type</th><th align="center">Dispatch FP8 #EP</th><th align="center">Bottleneck bandwidth</th><th align="center">Combine BF16 #EP</th><th align="center">Bottleneck bandwidth</th></tr></thead><tbody><tr><td align="center">Intranode</td><td align="center">8</td><td align="center">320 GB/s (NVLink)</td><td align="center">8</td><td align="center">319 GB/s (NVLink)</td></tr><tr><td align="center">Internode</td><td align="center">16</td><td align="center">50 GB/s (RDMA)</td><td align="center">16</td><td align="center">18 GB/s (RDMA)</td></tr><tr><td align="center">Internode</td><td align="center">24</td><td align="center">53 GB/s (RDMA)</td><td align="center">24</td><td align="center">26 GB/s (RDMA)</td></tr><tr><td align="center">Internode</td><td align="center">32</td><td align="center">54 GB/s (RDMA)</td><td align="center">32</td><td align="center">43 GB/s (RDMA)</td></tr></tbody></table>
<p>Across different EP sizes, the dispatch bandwidth exceeds 50 GB/s, while the combine bandwidth stabilizes around 40 GB/s. The slightly lower combine bandwidth reflects the additional overhead of the combine operation (e.g., accumulation and reduction across experts). We are still investigating the relatively lower combine throughput compared to dispatch at EP=16.</p>
<p>On a small testbed with GH200, we observe that UCCL-EP even outperforms the original DeepEP. We are surprised by the results, and hypothesize two reasons: the fast NVLink-C2C interconnect with <strong>CPU-GPU cache coherence</strong> on GH200 makes CPU-GPU communication very efficient; and the internal overhead of nvshmem. That said, we would like to verify the finding on larger testbeds.</p>
<p>Benchmark code and instructions can be found <a href="https://github.com/uccl-project/uccl/tree/main/ep#benchmark">here</a>.</p>
<hr>
<h2 id="uccl-ep-roadmap">UCCL EP Roadmap</h2>
<p>UCCL-EP is still in active development. We plan to release a formal post on application-level performance as well as performance on AMD GPUs and other NIC vendors. Our current roadmap includes:</p>
<ul>
<li>Further improving UCCL-EP performance on EFA</li>
<li>Finishing porting to AMD GPUs and Broadcom NICs (PR <a href="https://github.com/uccl-project/uccl/pull/457">#457</a>)</li>
<li>Advanced flow control and congestion management in the CPU</li>
<li>Integrating into vLLM and SGLang—contributions are much welcomed!</li>
</ul>
<hr>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>We thank AWS, Lambda Labs for providing us with the main testbeds. We especially thank Kaichao You, Zhen Huang, Zhenyu Gu, Costin Raiciu, Scott Shenker, Ion Stoica for their discussions and feedbacks. This research is supported by gifts from Accenture, AMD, Anyscale, AWS, Broadcom, Cisco, Google, IBM, Intel, Intesa Sanpaolo, Lambda, Lightspeed, Mibura, Microsoft, NVIDIA, Samsung SDS, and SAP.</p> </div> <div class="prose-a:no-underline"> <span class="mb-2 mr-2 inline-block rounded-full bg-neutral-200 px-3 py-1 text-sm hover:bg-neutral-500 dark:bg-neutral-600"> <a href="/tags/MoE/1/">MoE</a> </span><span class="mb-2 mr-2 inline-block rounded-full bg-neutral-200 px-3 py-1 text-sm hover:bg-neutral-500 dark:bg-neutral-600"> <a href="/tags/DeepEP/1/">DeepEP</a> </span><span class="mb-2 mr-2 inline-block rounded-full bg-neutral-200 px-3 py-1 text-sm hover:bg-neutral-500 dark:bg-neutral-600"> <a href="/tags/IBGDA/1/">IBGDA</a> </span><span class="mb-2 mr-2 inline-block rounded-full bg-neutral-200 px-3 py-1 text-sm hover:bg-neutral-500 dark:bg-neutral-600"> <a href="/tags/RDMA/1/">RDMA</a> </span> </div> <div class="flex justify-between mt-4"> <small>Publish on <span>2025-10-27</span></small> </div> </article> <div class="mt-4"> <div class="grid grid-cols-1 gap-4 md:grid-cols-3"> <div class="relative mb-4 overflow-hidden rounded-xl bg-white transition-transform duration-500 hover:-translate-y-1 hover:scale-105 dark:bg-neutral-900"> <a href="/posts/kv-transfer-engine/"> <picture> <source srcset="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/kv-transfer-engine/kv-transfer-engine.png 392w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/kv-transfer-engine/kv-transfer-engine.png 700w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/kv-transfer-engine/kv-transfer-engine.png 980w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/kv-transfer-engine/kv-transfer-engine.png 1960w" type="image/avif" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px">  <img src="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/kv-transfer-engine/kv-transfer-engine.png" srcset="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/kv-transfer-engine/kv-transfer-engine.png 392w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/kv-transfer-engine/kv-transfer-engine.png 700w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/kv-transfer-engine/kv-transfer-engine.png 980w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/kv-transfer-engine/kv-transfer-engine.png 1960w" alt="KV transfer engine" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px" width="1024" height="1024" loading="lazy" decoding="async" class="mx-auto w-full max-w-full rounded-lg"> </picture> <div class="absolute bottom-0 end-0 start-0 bg-gradient-to-t p-4 md:p-5"> <div class="mt-16 flex items-center gap-4 text-xs text-white"> <span>NIXL NCCL RCCL Mooncake RDMA</span> <span>2025-08-13</span> </div> <h2 class="mt-2 text-lg font-bold text-white">Everything You Want to Know about KV Cache Transfer Engine</h2> </div> </a> </div><div class="relative mb-4 overflow-hidden rounded-xl bg-white transition-transform duration-500 hover:-translate-y-1 hover:scale-105 dark:bg-neutral-900"> <a href="/posts/debug-nccl/"> <picture> <source srcset="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/nccl-debug/uccl-debug.png 392w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/nccl-debug/uccl-debug.png 700w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/nccl-debug/uccl-debug.png 980w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/nccl-debug/uccl-debug.png 1960w" type="image/avif" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px">  <img src="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/nccl-debug/uccl-debug.png" srcset="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/nccl-debug/uccl-debug.png 392w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/nccl-debug/uccl-debug.png 700w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/nccl-debug/uccl-debug.png 980w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/nccl-debug/uccl-debug.png 1960w" alt="About" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px" width="1024" height="1024" loading="lazy" decoding="async" class="mx-auto w-full max-w-full rounded-lg"> </picture> <div class="absolute bottom-0 end-0 start-0 bg-gradient-to-t p-4 md:p-5"> <div class="mt-16 flex items-center gap-4 text-xs text-white"> <span>NCCL RCCL RDMA</span> <span>2025-06-30</span> </div> <h2 class="mt-2 text-lg font-bold text-white">How to Debug NCCL Performance Issues for ML Workloads?</h2> </div> </a> </div><div class="relative mb-4 overflow-hidden rounded-xl bg-white transition-transform duration-500 hover:-translate-y-1 hover:scale-105 dark:bg-neutral-900"> <a href="/posts/about-uccl/"> <picture> <source srcset="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/about-uccl/uccl_tran_cover.png 392w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/about-uccl/uccl_tran_cover.png 700w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/about-uccl/uccl_tran_cover.png 980w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/about-uccl/uccl_tran_cover.png 1960w" type="image/avif" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px">  <img src="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/about-uccl/uccl_tran_cover.png" srcset="https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/about-uccl/uccl_tran_cover.png 392w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/about-uccl/uccl_tran_cover.png 700w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/about-uccl/uccl_tran_cover.png 980w, https://raw.githubusercontent.com/uccl-project/uccl-project.github.io/main/assets/about-uccl/uccl_tran_cover.png 1960w" alt="About" sizes="(max-width: 360px) 392px, 
           (max-width: 720px) 700px, 
           (max-width: 1600px) 980px, 
           1960px" width="1024" height="1024" loading="lazy" decoding="async" class="mx-auto w-full max-w-full rounded-lg"> </picture> <div class="absolute bottom-0 end-0 start-0 bg-gradient-to-t p-4 md:p-5"> <div class="mt-16 flex items-center gap-4 text-xs text-white"> <span>Networking AI RDMA</span> <span>2025-05-26</span> </div> <h2 class="mt-2 text-lg font-bold text-white">UCCL-Tran: An Extensible Software Transport Layer for GPU Networking</h2> </div> </a> </div> </div> </div> </main>  </main> <footer class="mt-auto w-full max-w-[85rem] py-10 mx-auto" data-astro-cid-sz7xmlte> <nav class="mx-auto w-full max-w-[85rem] px-4" aria-label="Footer" data-astro-cid-sz7xmlte> <div class="footer-wrapper" style="display: grid; grid-template-columns: 1fr auto 1fr; align-items: center; gap: 2rem;" data-astro-cid-sz7xmlte> <!-- Left: Brand --> <div class="footer-left" style="text-align: left; justify-self: start;" data-astro-cid-sz7xmlte> <a class="flex-none text-sm text-neutral-500 hover:text-neutral-800 dark:text-neutral-500 dark:hover:text-neutral-200" href="/" aria-label="Brand" data-astro-cid-sz7xmlte>UCCL &copy; 2025</a> </div> <!-- Center: Footer Links --> <div class="footer-center" style="text-align: center; justify-self: center;" data-astro-cid-sz7xmlte> <div class="flex flex-row gap-5 items-center flex-wrap justify-center" data-astro-cid-sz7xmlte> <a href="https://sky.cs.berkeley.edu/" class="inline-flex gap-x-2 text-sm text-neutral-500 hover:text-neutral-800 dark:text-neutral-500 dark:hover:text-neutral-200" data-astro-cid-sz7xmlte="true"> UC Berkeley Sky Lab </a><a href="https://github.com/artsy-lab" class="inline-flex gap-x-2 text-sm text-neutral-500 hover:text-neutral-800 dark:text-neutral-500 dark:hover:text-neutral-200" data-astro-cid-sz7xmlte="true"> UC Davis ArtSy Lab </a> </div> </div> <!-- Right: Social Links --> <div class="footer-right" style="text-align: right; justify-self: end;" data-astro-cid-sz7xmlte> <button type="button" class="relative inline-flex h-12 w-12 items-center gap-x-2 bg-white px-4 py-3 text-neutral-500 hover:text-neutral-800 disabled:pointer-events-none disabled:opacity-50  dark:text-neutral-500 dark:hover:text-neutral-200 dark:bg-neutral-900 dark:hover:bg-neutral-900" data-astro-cid-sz7xmlte> <a href="https://github.com/uccl-project" class="absolute inset-0 z-10" aria-label="GitHub" data-astro-cid-sz7xmlte></a> <svg width="1em" height="1em" class="icon-base" data-astro-cid-sz7xmlte="true" data-icon="tabler:brand-github">   <symbol id="ai:tabler:brand-github" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2c2.8-.3 5.5-1.4 5.5-6a4.6 4.6 0 0 0-1.3-3.2a4.2 4.2 0 0 0-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3 0 0 0-6.2 0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2 0 0 0-.1 3.2A4.6 4.6 0 0 0 4 9.5c0 4.6 2.7 5.7 5.5 6c-.6.6-.6 1.2-.5 2V21"/></symbol><use href="#ai:tabler:brand-github"></use>  </svg> </button> </div> </div> </nav> </footer> </body></html>